<!DOCTYPE html>
<html>
<head>
    <title>Puzzle Detector Pro</title>
    <script src="opencv.js"></script>
    <style>
        body { margin: 0; padding: 0; overflow: hidden; font-family: Arial, sans-serif; background: #1a1a2e; color: #e0e0e0; }
        .container { display: flex; flex-direction: column; height: 100vh; }
        .half-section { position: relative; height: 50vh; background: #16213e; border: 2px solid #0f3460; }
        .overlay-text { position: absolute; bottom: 20px; left: 50%; transform: translateX(-50%); color: rgba(255,255,255,0.7); font-size: 2em; z-index: 2; background: rgba(0,0,0,0.5); padding: 10px; width: 100%; text-align: center; }
        canvas, video { width: 100%; height: 100%; object-fit: cover; position: absolute; top: 0; left: 0; }
        .detection-outline { position: absolute; width: 80%; height: 80%; top: 10%; left: 10%; opacity: 0.5; pointer-events: none; }
        .worker-status { position: fixed; top: 10px; right: 10px; color: #0f0; font-family: monospace; background: rgba(0,0,0,0.5); padding: 5px; border-radius: 3px; }
        .match-overlay { position: absolute; bottom: 10px; left: 50%; transform: translateX(-50%); background: rgba(0,0,0,0.7); color: white; padding: 10px; border-radius: 5px; max-width: 90%; text-align: center; z-index: 10; display: none; }
        #lowerSection { display: none; } /* Hide lower section by default */
    </style>
</head>
<body>
    <div class="container">
        <div class="half-section" id="upperSection">
            <video id="upperVideo"></video>
            <canvas id="referenceCanvas"></canvas>
            <div id="upperOverlay" class="overlay-text">Tap to capture reference puzzle image</div>
        </div>
        <div class="half-section" id="lowerSection">
            <video id="lowerVideo"></video>
            <canvas id="detectionCanvas"></canvas>
            <svg class="detection-outline" viewBox="0 0 500 500" preserveAspectRatio="xMidYMid meet">
                <path style="fill: none; stroke: rgba(0, 255, 0, 0.7); stroke-width: 10;" d="M260.91 55.476c-15.2.56-32.24 5.654-41.34 16.563-13.23 28.19 18.91 15.173 22.69 34.691 3.78 19.51-18.91 20.59-18.91 20.59h-97.75l.13 96.94s1.08 22.68 20.59 18.9c15.86-3.07 10.23-24.87 22.69-25.84 2.87-.22 6.71.68 12 3.16 10.91 9.09 16 26.14 16.56 41.34.21 5.61-.28 10.89-1.25 15.5-.02.2-.07.42-.09.63-1.7 13.11-6.77 26.41-15.97 34.09-28.19 13.23-15.18-18.91-34.69-22.69-14.22-2.75-18.61 8.48-19.97 14.81v102.91l98.1-.78s22.68-1.08 18.9-20.59c-3.78-19.52-35.88-6.5-22.65-34.69 9.09-10.91 26.11-16.01 41.31-16.56 5.61-.21 10.89.28 15.5 1.25.2.02.42.06.62.09 13.12 1.69 26.45 6.76 34.13 15.97 13.23 28.19-18.91 15.17-22.69 34.69-3.78 19.51 18.91 20.59 18.91 20.59l97.18.03v-102.09c1.39-6.36 5.81-17.46 19.94-14.72 19.52 3.78 6.5 35.91 34.69 22.69 9.21-7.68 14.27-21.02 15.97-34.13.02-.2.07-.39.09-.59.97-4.62 1.46-9.89 1.25-15.5-.56-15.2-5.65-32.25-16.56-41.35-28.19-13.23-15.17 18.91-34.69 22.69-19.51 3.78-20.59-18.91-20.59-18.91l-.1-97.84h-102.15c-6.41-1.48-16.97-5.99-14.28-19.84 3.78-19.518 35.88-6.5 22.65-34.691-7.67-9.207-20.98-14.275-34.09-15.969-.21-.026-.42-.069-.63-.094-4.61-.966-9.88-1.456-15.5-1.25z"/>
            </svg>
            <div id="lowerOverlay" class="overlay-text">Hold puzzle piece inside outline</div>
        </div>
    </div>
    <div class="worker-status" id="workerStatus">Initializing...</div>
    <div class="match-overlay" id="matchOverlay"></div>
</body>
<script>
    let referenceImage = null;
    let isDetecting = false;
    let isProcessing = false;
    const DETECTION_THRESHOLD = 0.18; // Adjust this if needed
    const WINDOW_SIZE = 100;

    // Utility Functions
    const log = (msg, type = 'info') => {
        console[type](`[${type.toUpperCase()}] ${msg}`);
        document.getElementById('workerStatus').textContent = msg;
    };

    // Camera Setup
    function initializeApplication() {
        navigator.mediaDevices.getUserMedia({ video: { facingMode: 'environment' } })
            .then(stream => {
                const upperVideo = document.getElementById('upperVideo');
                const lowerVideo = document.getElementById('lowerVideo');
                upperVideo.srcObject = lowerVideo.srcObject = stream;

                upperVideo.onloadedmetadata = () => {
                    upperVideo.play();
                    log('Upper video stream ready');
                };
                lowerVideo.onloadedmetadata = () => {
                    lowerVideo.play();
                    log('Lower video stream ready');
                };
                log('Camera stream acquired');
            })
            .catch(err => log(`Camera access error: ${err.message}`, 'error'));
    }

    // SVG Path Parser
    function parseSVGPath() {
        const path = document.querySelector('.detection-outline path');
        const points = [];
        path.getAttribute('d').replace(/([MLC])([^A-Z]*)/g, (_, cmd, coords) => {
            const nums = coords.trim().split(/[\s,]+/).map(Number);
            for (let i = 0; i < nums.length; i += 2) {
                if (cmd === 'C' && i === 4) points.push({x: nums[i], y: nums[i+1]});
                else if (cmd !== 'C') points.push({x: nums[i], y: nums[i+1]});
            }
        });
        return points;
    }

    // Capture Reference Image
    function captureReferenceImage() {
        const video = document.getElementById('upperVideo');
        const refCanvas = document.getElementById('referenceCanvas');
        
        // Size the canvas to match the video dimensions
        refCanvas.width = video.videoWidth;
        refCanvas.height = video.videoHeight;
        const ctx = refCanvas.getContext('2d');
        
        // Draw the current video frame to the reference canvas
        ctx.drawImage(video, 0, 0, refCanvas.width, refCanvas.height);
        
        // Get the image data for the central portion to use for detection
        const centerX = Math.floor((refCanvas.width - WINDOW_SIZE) / 2);
        const centerY = Math.floor((refCanvas.height - WINDOW_SIZE) / 2);
        referenceImage = ctx.getImageData(centerX, centerY, WINDOW_SIZE, WINDOW_SIZE);
        
        // Update UI
        document.getElementById('upperOverlay').textContent = 'Reference image captured - Tap to recapture';
        document.getElementById('lowerSection').style.display = 'block';
        isDetecting = true;
        log('Reference captured');
        
        // Start detection process
        processDetection();
    }

    // Reset the app to initial state
    function resetApplication() {
        referenceImage = null;
        isDetecting = false;
        document.getElementById('upperOverlay').textContent = 'Tap to capture reference puzzle image';
        document.getElementById('lowerSection').style.display = 'none';
        document.getElementById('matchOverlay').style.display = 'none';
        document.getElementById('workerStatus').textContent = 'Ready for reference capture';
        
        // Clear canvases
        const refCanvas = document.getElementById('referenceCanvas');
        const ctx = refCanvas.getContext('2d');
        ctx.clearRect(0, 0, refCanvas.width, refCanvas.height);
    }

    // Process Detection
    function processDetection() {
        if (!isDetecting || !referenceImage || isProcessing) {
            setTimeout(processDetection, 200);
            return;
        }
        
        isProcessing = true;

        try {
            const video = document.getElementById('lowerVideo');
            const canvas = document.getElementById('detectionCanvas');
            const status = document.getElementById('workerStatus');
            const overlay = document.getElementById('matchOverlay');
            
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            const ctx = canvas.getContext('2d');
            ctx.drawImage(video, 0, 0);

            // Proceed only if OpenCV is available
            if (typeof cv === 'undefined' || !cv.Mat) {
                status.textContent = 'OpenCV not available';
                setTimeout(processDetection, 1000);
                isProcessing = false;
                return;
            }

            // Create source matrices
            const refMat = cv.matFromImageData(referenceImage);
            const detMat = cv.matFromImageData(ctx.getImageData(0, 0, canvas.width, canvas.height));
            
            // Convert to grayscale
            const refGray = new cv.Mat();
            const detGray = new cv.Mat();
            cv.cvtColor(refMat, refGray, cv.COLOR_RGBA2GRAY);
            cv.cvtColor(detMat, detGray, cv.COLOR_RGBA2GRAY);
            
            // Process with multiple scales
            const scales = [0.5, 0.75, 1.0, 1.25, 1.5, 2.0];
            const matches = [];
            
            for (let scale of scales) {
                const scaledSize = new cv.Size(
                    Math.round(WINDOW_SIZE * scale),
                    Math.round(WINDOW_SIZE * scale)
                );
                
                // Skip invalid sizes
                if (scaledSize.width > detGray.cols || 
                    scaledSize.height > detGray.rows || 
                    scaledSize.width <= 0 || 
                    scaledSize.height <= 0) {
                    continue;
                }
                
                const scaledRef = new cv.Mat();
                const result = new cv.Mat();
                
                try {
                    cv.resize(refGray, scaledRef, scaledSize);
                    cv.matchTemplate(detGray, scaledRef, result, cv.TM_CCOEFF_NORMED);
                    
                    const minMax = cv.minMaxLoc(result);
                    if (minMax.maxVal >= DETECTION_THRESHOLD) {
                        matches.push({
                            confidence: minMax.maxVal,
                            scale: scale,
                            x: minMax.maxLoc.x,
                            y: minMax.maxLoc.y,
                            width: scaledSize.width,
                            height: scaledSize.height
                        });
                    }
                } finally {
                    scaledRef.delete();
                    result.delete();
                }
            }
            
            // Display results
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            ctx.drawImage(video, 0, 0);
            
            if (matches.length > 0) {
                // Sort matches by confidence
                matches.sort((a, b) => b.confidence - a.confidence);
                const best = matches[0];
                
                status.textContent = `Match: ${(best.confidence * 100).toFixed(1)}%`;
                overlay.innerHTML = `Confidence: ${(best.confidence * 100).toFixed(1)}%<br>Scale: ${(best.scale * 100).toFixed(0)}%`;
                overlay.style.display = 'block';
                
                const svgPoints = parseSVGPath();
                ctx.beginPath();
                ctx.strokeStyle = 'lime';
                ctx.lineWidth = 3;
                const scaleFactor = best.scale * (best.width / 500);
                const offsetX = best.x;
                const offsetY = best.y;
                
                // Draw the SVG outline at the detected position
                svgPoints.forEach((point, i) => {
                    const x = offsetX + (point.x * scaleFactor);
                    const y = offsetY + (point.y * scaleFactor);
                    i === 0 ? ctx.moveTo(x, y) : ctx.lineTo(x, y);
                });
                ctx.closePath();
                ctx.stroke();
                
                // Draw matching region rectangle
                ctx.strokeStyle = 'yellow';
                ctx.lineWidth = 2;
                ctx.strokeRect(best.x, best.y, best.width, best.height);
            } else {
                status.textContent = 'No matches found';
                overlay.style.display = 'none';
            }
            
            // Clean up
            refMat.delete();
            detMat.delete();
            refGray.delete();
            detGray.delete();
            
        } catch (err) {
            console.error('Detection error:', err);
            document.getElementById('workerStatus').textContent = 'Detection Error: ' + err.message;
        } finally {
            isProcessing = false;
            // Continue processing at a reasonable frame rate
            setTimeout(processDetection, 100);
        }
    }

    // Initialization
    document.addEventListener('DOMContentLoaded', () => {
        const interval = setInterval(() => {
            if (typeof cv !== 'undefined' && cv.Mat) {
                clearInterval(interval);
                log('OpenCV loaded, initializing application');
                initializeApplication();
                
                // Set up event handlers
                document.getElementById('upperSection').addEventListener('click', captureReferenceImage);
                document.getElementById('lowerSection').addEventListener('dblclick', resetApplication);
            }
        }, 500);
    });
</script>
</html>
