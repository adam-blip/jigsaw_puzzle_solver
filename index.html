<!DOCTYPE html>
<html>
<head>
    <title>Puzzle Detector Pro</title>
    <script src="opencv.js"></script>
    <style>
        body { margin: 0; padding: 0; overflow: hidden; font-family: Arial, sans-serif; background: #1a1a2e; color: #e0e0e0; }
        .container { display: flex; flex-direction: column; height: 100vh; }
        .half-section { position: relative; height: 50vh; background: #16213e; border: 2px solid #0f3460; }
        .overlay-text { position: absolute; bottom: 20px; left: 50%; transform: translateX(-50%); color: rgba(255,255,255,0.7); font-size: 2em; z-index: 2; background: rgba(0,0,0,0.5); padding: 10px; width: 100%; text-align: center; }
        canvas, video { width: 100%; height: 100%; object-fit: cover; position: absolute; top: 0; left: 0; }
        .detection-outline { position: absolute; width: 80%; height: 80%; top: 10%; left: 10%; opacity: 0.5; pointer-events: none; }
        .worker-status { position: fixed; top: 10px; right: 10px; color: #0f0; font-family: monospace; background: rgba(0,0,0,0.5); padding: 5px; border-radius: 3px; }
        .match-outline { position: absolute; border: 3px solid lime; pointer-events: none; display: none; z-index: 10; box-shadow: 0 0 15px rgba(0,255,0,0.7); }
        .match-overlay { position: absolute; bottom: 10px; left: 50%; transform: translateX(-50%); background: rgba(0,0,0,0.7); color: white; padding: 10px; border-radius: 5px; max-width: 90%; text-align: center; z-index: 10; display: none; }
        #lowerSection { display: none; } /* Hide lower section by default */
        #processingIndicator { position: fixed; top: 40px; right: 10px; color: #ff0; font-family: monospace; background: rgba(0,0,0,0.5); padding: 5px; border-radius: 3px; display: none; }
    </style>
</head>
<body>
    <div class="container">
        <div class="half-section" id="upperSection">
            <video id="upperVideo"></video>
            <canvas id="referenceCanvas"></canvas>
            <div id="matchIndicator" class="match-outline"></div>
            <div id="upperOverlay" class="overlay-text">Tap to capture complete puzzle reference</div>
        </div>
        <div class="half-section" id="lowerSection">
            <video id="lowerVideo"></video>
            <canvas id="detectionCanvas"></canvas>
            <svg class="detection-outline" viewBox="0 0 500 500" preserveAspectRatio="xMidYMid meet">
                <path style="fill: none; stroke: rgba(0, 255, 0, 0.7); stroke-width: 10;" d="M260.91 55.476c-15.2.56-32.24 5.654-41.34 16.563-13.23 28.19 18.91 15.173 22.69 34.691 3.78 19.51-18.91 20.59-18.91 20.59h-97.75l.13 96.94s1.08 22.68 20.59 18.9c15.86-3.07 10.23-24.87 22.69-25.84 2.87-.22 6.71.68 12 3.16 10.91 9.09 16 26.14 16.56 41.34.21 5.61-.28 10.89-1.25 15.5-.02.2-.07.42-.09.63-1.7 13.11-6.77 26.41-15.97 34.09-28.19 13.23-15.18-18.91-34.69-22.69-14.22-2.75-18.61 8.48-19.97 14.81v102.91l98.1-.78s22.68-1.08 18.9-20.59c-3.78-19.52-35.88-6.5-22.65-34.69 9.09-10.91 26.11-16.01 41.31-16.56 5.61-.21 10.89.28 15.5 1.25.2.02.42.06.62.09 13.12 1.69 26.45 6.76 34.13 15.97 13.23 28.19-18.91 15.17-22.69 34.69-3.78 19.51 18.91 20.59 18.91 20.59l97.18.03v-102.09c1.39-6.36 5.81-17.46 19.94-14.72 19.52 3.78 6.5 35.91 34.69 22.69 9.21-7.68 14.27-21.02 15.97-34.13.02-.2.07-.39.09-.59.97-4.62 1.46-9.89 1.25-15.5-.56-15.2-5.65-32.25-16.56-41.35-28.19-13.23-15.17 18.91-34.69 22.69-19.51 3.78-20.59-18.91-20.59-18.91l-.1-97.84h-102.15c-6.41-1.48-16.97-5.99-14.28-19.84 3.78-19.518 35.88-6.5 22.65-34.691-7.67-9.207-20.98-14.275-34.09-15.969-.21-.026-.42-.069-.63-.094-4.61-.966-9.88-1.456-15.5-1.25z"/>
            </svg>
            <div id="lowerOverlay" class="overlay-text">Hold puzzle piece inside outline</div>
        </div>
    </div>
    <div class="worker-status" id="workerStatus">Initializing...</div>
    <div class="match-overlay" id="matchOverlay"></div>
    <div id="processingIndicator">Processing...</div>
</body>
<script>
    // Performance-optimized variables
    let referenceImage = null;
    let puzzlePieceTemplate = null;
    let isDetecting = false;
    let isProcessing = false;
    let processingTime = 0;
    let frameCount = 0;
    let lastFrameTime = 0;
    const DETECTION_THRESHOLD = 0.45;
    const MATCH_CONFIDENCE_THRESHOLD = 0.60;
    const HIGH_CONFIDENCE_THRESHOLD = 0.75;
    const FRAME_SKIP = 2; // Process only every Nth frame
    let skipCounter = 0;
    let referenceWidth = 0;
    let referenceHeight = 0;
    
    // Cached OpenCV objects to prevent reallocation
    let cachedRefMat = null;
    let cachedRefGray = null;
    let cachedBlurredRef = null;
    
    // Adaptive rotation strategy
    let rotationMode = 'coarse';
    let lastConfidence = 0;
    let lastMatchRegion = null;
    let stableMatchCount = 0;
    
    // Optimization flags
    const useROI = true; // Use region of interest for focused processing
    let roi = null; // Will store the current region of interest
    
    // Utility Functions
    const log = (msg, type = 'info') => {
        console[type](`[${type.toUpperCase()}] ${msg}`);
        document.getElementById('workerStatus').textContent = msg;
    };
    
    // Performance monitoring
    function updatePerformanceStats(startTime) {
        const endTime = performance.now();
        processingTime += (endTime - startTime);
        frameCount++;
        
        if (frameCount % 10 === 0) {
            const avgProcessingTime = processingTime / frameCount;
            const fps = 1000 / avgProcessingTime;
            document.getElementById('processingIndicator').textContent = 
                `Avg: ${avgProcessingTime.toFixed(1)}ms | FPS: ${fps.toFixed(1)}`;
            document.getElementById('processingIndicator').style.display = 'block';
        }
    }
    
    // Camera Setup - Optimized for higher quality
    function initializeApplication() {
        // Request the highest possible resolution the device can handle
        const constraints = {
            video: {
                facingMode: 'environment',
                width: { ideal: 1920 },
                height: { ideal: 1080 }
            }
        };
        
        navigator.mediaDevices.getUserMedia(constraints)
            .then(stream => {
                const upperVideo = document.getElementById('upperVideo');
                const lowerVideo = document.getElementById('lowerVideo');
                upperVideo.srcObject = lowerVideo.srcObject = stream;
                
                // Get actual stream settings
                const videoTrack = stream.getVideoTracks()[0];
                const capabilities = videoTrack.getCapabilities();
                log(`Camera: ${capabilities.width.max}x${capabilities.height.max}`);
                
                upperVideo.onloadedmetadata = () => {
                    upperVideo.play();
                    log('Upper video stream ready');
                };
                lowerVideo.onloadedmetadata = () => {
                    lowerVideo.play();
                    log('Lower video stream ready');
                };
            })
            .catch(err => log(`Camera access error: ${err.message}`, 'error'));
    }
    
    // Capture Reference Image (complete puzzle)
    function captureReferenceImage() {
        if (isDetecting) {
            resetApplication();
            return;
        }
        
        const video = document.getElementById('upperVideo');
        const refCanvas = document.getElementById('referenceCanvas');
        
        // Size the canvas to match the video dimensions
        refCanvas.width = video.videoWidth;
        refCanvas.height = video.videoHeight;
        referenceWidth = refCanvas.width;
        referenceHeight = refCanvas.height;
        
        const ctx = refCanvas.getContext('2d');
        
        // Draw the current video frame to the reference canvas
        ctx.drawImage(video, 0, 0, refCanvas.width, refCanvas.height);
        
        // Get the full reference image data
        referenceImage = ctx.getImageData(0, 0, refCanvas.width, refCanvas.height);
        
        // Pre-process the reference image once for OpenCV
        if (typeof cv !== 'undefined' && cv.Mat) {
            // Free any previously cached matrices
            if (cachedRefMat) cachedRefMat.delete();
            if (cachedRefGray) cachedRefGray.delete();
            if (cachedBlurredRef) cachedBlurredRef.delete();
            
            // Create new cached matrices
            cachedRefMat = cv.matFromImageData(referenceImage);
            cachedRefGray = new cv.Mat();
            cachedBlurredRef = new cv.Mat();
            
            // Pre-process reference image
            cv.cvtColor(cachedRefMat, cachedRefGray, cv.COLOR_RGBA2GRAY);
            cv.GaussianBlur(cachedRefGray, cachedBlurredRef, new cv.Size(3, 3), 0);
        }
        
        // Update UI
        document.getElementById('upperOverlay').textContent = 'Reference captured - Tap to recapture';
        document.getElementById('lowerSection').style.display = 'block';
        isDetecting = true;
        
        // Reset performance metrics
        processingTime = 0;
        frameCount = 0;
        lastFrameTime = performance.now();
        
        // Start detection process
        processDetection();
    }
    
    // Reset the app to initial state
    function resetApplication() {
        referenceImage = null;
        puzzlePieceTemplate = null;
        isDetecting = false;
        
        // Free OpenCV resources
        if (cachedRefMat) {
            cachedRefMat.delete();
            cachedRefMat = null;
        }
        if (cachedRefGray) {
            cachedRefGray.delete();
            cachedRefGray = null;
        }
        if (cachedBlurredRef) {
            cachedBlurredRef.delete();
            cachedBlurredRef = null;
        }
        
        // Reset UI elements
        document.getElementById('upperOverlay').textContent = 'Tap to capture complete puzzle reference';
        document.getElementById('lowerSection').style.display = 'none';
        document.getElementById('matchOverlay').style.display = 'none';
        document.getElementById('matchIndicator').style.display = 'none';
        document.getElementById('workerStatus').textContent = 'Ready for reference capture';
        document.getElementById('processingIndicator').style.display = 'none';
        
        // Clear canvases
        const refCanvas = document.getElementById('referenceCanvas');
        const ctx = refCanvas.getContext('2d');
        ctx.clearRect(0, 0, refCanvas.width, refCanvas.height);
        
        // Reset optimization variables
        rotationMode = 'coarse';
        lastConfidence = 0;
        lastMatchRegion = null;
        stableMatchCount = 0;
        roi = null;
    }
    
    // Optimize template capture to use a fixed size relative to video
    function capturePuzzlePieceTemplate() {
        const video = document.getElementById('lowerVideo');
        const canvas = document.createElement('canvas');
        
        // Use a consistent template size optimized for detection
        const templateWidth = Math.round(video.videoWidth * 0.35);
        const templateHeight = Math.round(video.videoHeight * 0.35);
        
        // Center coordinates
        const centerX = video.videoWidth / 2;
        const centerY = video.videoHeight / 2;
        
        canvas.width = templateWidth;
        canvas.height = templateHeight;
        const ctx = canvas.getContext('2d');
        
        // Extract the template from center of video
        ctx.drawImage(
            video, 
            centerX - templateWidth/2, 
            centerY - templateHeight/2,
            templateWidth,
            templateHeight,
            0, 0, 
            templateWidth, 
            templateHeight
        );
        
        return ctx.getImageData(0, 0, templateWidth, templateHeight);
    }
    
    // Optimized rotate function using WebGL when available
    function rotateImage(mat, angleDegrees) {
        // Convert degrees to radians for calculations
        const angleRadians = angleDegrees * Math.PI / 180;
        
        // Calculate dimensions
        const width = mat.cols;
        const height = mat.rows;
        const center = new cv.Point(width / 2, height / 2);
        
        // Calculate new size needed
        const cosAngle = Math.abs(Math.cos(angleRadians));
        const sinAngle = Math.abs(Math.sin(angleRadians));
        const newWidth = Math.round(height * sinAngle + width * cosAngle);
        const newHeight = Math.round(height * cosAngle + width * sinAngle);
        
        // Create rotation matrix with size adjustment to prevent cropping
        const rotationMatrix = cv.getRotationMatrix2D(center, angleDegrees, 1);
        rotationMatrix.data[2] += (newWidth / 2) - center.x;
        rotationMatrix.data[5] += (newHeight / 2) - center.y;
        
        // Create output matrix and perform rotation
        const rotated = new cv.Mat();
        const dsize = new cv.Size(newWidth, newHeight);
        
        // Use border constant to ensure clean edges
        cv.warpAffine(
            mat, 
            rotated, 
            rotationMatrix, 
            dsize, 
            cv.INTER_LINEAR, 
            cv.BORDER_CONSTANT, 
            new cv.Scalar(0, 0, 0, 255)
        );
        
        // Clean up
        rotationMatrix.delete();
        
        return rotated;
    }
    
    // Optimized rotation angles strategy
    function getRotationAngles() {
        // If we have a stable match with high confidence, use very focused angles
        if (lastMatchRegion && lastConfidence > HIGH_CONFIDENCE_THRESHOLD && stableMatchCount > 3) {
            // Use a narrow range around the last successful angle
            const baseAngle = lastMatchRegion.rotation;
            return [baseAngle-5, baseAngle-2, baseAngle, baseAngle+2, baseAngle+5];
        }
        
        // Standard rotation modes
        if (rotationMode === 'coarse') {
            return [0, 90, 180, 270];
        } else if (rotationMode === 'medium') {
            return [0, 45, 90, 135, 180, 225, 270, 315];
        } else {
            // Fine rotation mode
            return [0, 15, 30, 45, 60, 75, 90, 105, 120, 135, 150, 165, 180, 
                   195, 210, 225, 240, 255, 270, 285, 300, 315, 330, 345];
        }
    }
    
    // Get optimal scales based on adaptive strategy
    function getOptimalScales() {
        // If we have a stable match, use focused scales
        if (lastMatchRegion && lastConfidence > HIGH_CONFIDENCE_THRESHOLD && stableMatchCount > 3) {
            // Use a narrow range around the last successful scale
            const baseScale = lastMatchRegion.scale;
            return [baseScale*0.9, baseScale*0.95, baseScale, baseScale*1.05, baseScale*1.1];
        }
        
        // Default scales for each mode
        if (rotationMode === 'coarse') {
            return [0.3, 0.5, 0.7, 0.9, 1.1];
        } else if (rotationMode === 'medium') {
            return [0.4, 0.6, 0.8, 1.0, 1.2];
        } else {
            return [0.6, 0.8, 1.0, 1.2];
        }
    }
    
    // Main processing function - optimized for speed
    function processDetection() {
        if (!isDetecting || !referenceImage || !cachedBlurredRef) {
            setTimeout(processDetection, 200);
            return;
        }
        
        // Skip frames to improve performance
        skipCounter = (skipCounter + 1) % FRAME_SKIP;
        if (skipCounter !== 0) {
            requestAnimationFrame(processDetection);
            return;
        }
        
        // Avoid processing if we're still processing the previous frame
        if (isProcessing) {
            requestAnimationFrame(processDetection);
            return;
        }
        
        isProcessing = true;
        const startTime = performance.now();
        
        try {
            // Capture current puzzle piece
            puzzlePieceTemplate = capturePuzzlePieceTemplate();
            
            // Update detection canvas to show what's being processed
            const detectionCanvas = document.getElementById('detectionCanvas');
            const lowerVideo = document.getElementById('lowerVideo');
            detectionCanvas.width = lowerVideo.videoWidth;
            detectionCanvas.height = lowerVideo.videoHeight;
            const detCtx = detectionCanvas.getContext('2d');
            detCtx.drawImage(lowerVideo, 0, 0);
            
            // Create template Mat and preprocess
            const templateMat = cv.matFromImageData(puzzlePieceTemplate);
            const templateGray = new cv.Mat();
            cv.cvtColor(templateMat, templateGray, cv.COLOR_RGBA2GRAY);
            
            // Apply adaptive blur based on image size
            const blurSize = Math.max(3, Math.round(templateGray.cols / 100) * 2 + 1);
            const blurredTemplate = new cv.Mat();
            cv.GaussianBlur(templateGray, blurredTemplate, new cv.Size(blurSize, blurSize), 0);
            
            // Get optimal parameters based on current state
            const scales = getOptimalScales();
            const rotations = getRotationAngles();
            
            // Prepare for matching
            let bestMatch = null;
            
            // Define region of interest for focused processing
            let searchROI;
            if (useROI && lastMatchRegion && lastConfidence > MATCH_CONFIDENCE_THRESHOLD) {
                // Expand the search area around last match
                const margin = Math.max(lastMatchRegion.width, lastMatchRegion.height) * 0.5;
                const roiX = Math.max(0, lastMatchRegion.x - margin);
                const roiY = Math.max(0, lastMatchRegion.y - margin);
                const roiWidth = Math.min(cachedBlurredRef.cols - roiX, lastMatchRegion.width + 2 * margin);
                const roiHeight = Math.min(cachedBlurredRef.rows - roiY, lastMatchRegion.height + 2 * margin);
                
                searchROI = new cv.Rect(roiX, roiY, roiWidth, roiHeight);
                roi = { x: roiX, y: roiY, width: roiWidth, height: roiHeight };
            } else {
                // Search the entire reference image
                searchROI = new cv.Rect(0, 0, cachedBlurredRef.cols, cachedBlurredRef.rows);
                roi = null;
            }
            
            // Extract the region of interest
            const roiMat = cachedBlurredRef.roi(searchROI);
            
            // Process each rotation
            for (let rotation of rotations) {
                // Rotate the template
                const rotatedTemplate = rotation === 0 ? 
                    blurredTemplate.clone() : 
                    rotateImage(blurredTemplate, rotation);
                
                // Try each scale
                for (let scale of scales) {
                    const scaledSize = new cv.Size(
                        Math.round(rotatedTemplate.cols * scale),
                        Math.round(rotatedTemplate.rows * scale)
                    );
                    
                    // Skip invalid sizes
                    if (scaledSize.width >= roiMat.cols || 
                        scaledSize.height >= roiMat.rows || 
                        scaledSize.width <= 10 || 
                        scaledSize.height <= 10) {
                        continue;
                    }
                    
                    const scaledTemplate = new cv.Mat();
                    const result = new cv.Mat();
                    
                    try {
                        // Resize the template
                        cv.resize(rotatedTemplate, scaledTemplate, scaledSize, 0, 0, cv.INTER_AREA);
                        
                        // Match the template within ROI
                        cv.matchTemplate(roiMat, scaledTemplate, result, cv.TM_CCOEFF_NORMED);
                        
                        // Find best match
                        const minMax = cv.minMaxLoc(result);
                        if (minMax.maxVal >= DETECTION_THRESHOLD && 
                            (!bestMatch || minMax.maxVal > bestMatch.confidence)) {
                            
                            // Adjust coordinates based on ROI offset
                            bestMatch = {
                                confidence: minMax.maxVal,
                                scale: scale,
                                rotation: rotation,
                                x: minMax.maxLoc.x + (roi ? roi.x : 0),
                                y: minMax.maxLoc.y + (roi ? roi.y : 0),
                                width: scaledSize.width,
                                height: scaledSize.height
                            };
                        }
                    } finally {
                        scaledTemplate.delete();
                        result.delete();
                    }
                }
                
                // Clean up rotated template
                if (rotation !== 0) {
                    rotatedTemplate.delete();
                }
                
                // Early termination if we found a very good match
                if (bestMatch && bestMatch.confidence > HIGH_CONFIDENCE_THRESHOLD) {
                    break;
                }
            }
            
            // Release ROI matrix
            roiMat.delete();
            
            // Display match result
            const matchIndicator = document.getElementById('matchIndicator');
            const status = document.getElementById('workerStatus');
            
            if (bestMatch && bestMatch.confidence >= DETECTION_THRESHOLD) {
                // Update status
                status.textContent = `Match: ${(bestMatch.confidence * 100).toFixed(1)}%, Rot: ${bestMatch.rotation.toFixed(1)}Â°`;
                
                // Show match in the upper reference image
                matchIndicator.style.left = (bestMatch.x / referenceWidth * 100) + '%';
                matchIndicator.style.top = (bestMatch.y / referenceHeight * 100) + '%';
                matchIndicator.style.width = (bestMatch.width / referenceWidth * 100) + '%';
                matchIndicator.style.height = (bestMatch.height / referenceHeight * 100) + '%';
                matchIndicator.style.display = 'block';
                matchIndicator.style.transformOrigin = 'center center';
                matchIndicator.style.transform = `rotate(${bestMatch.rotation}deg)`;
                
                // Track match stability
                if (lastMatchRegion) {
                    const xDiff = Math.abs(lastMatchRegion.x - bestMatch.x);
                    const yDiff = Math.abs(lastMatchRegion.y - bestMatch.y);
                    const sizeDiff = Math.abs(lastMatchRegion.width - bestMatch.width);
                    const rotDiff = Math.abs(lastMatchRegion.rotation - bestMatch.rotation);
                    
                    // If match is stable, increment counter
                    if (xDiff < 20 && yDiff < 20 && sizeDiff < 20 && rotDiff < 15) {
                        stableMatchCount++;
                    } else {
                        stableMatchCount = 0;
                    }
                }
                
                // Update match state
                lastMatchRegion = bestMatch;
                lastConfidence = bestMatch.confidence;
                
                // Adapt rotation mode based on confidence
                if (bestMatch.confidence > 0.7) {
                    if (rotationMode === 'coarse') {
                        rotationMode = 'medium';
                    } else if (rotationMode === 'medium' && bestMatch.confidence > 0.8) {
                        rotationMode = 'fine';
                    }
                }
            } else {
                status.textContent = 'No matches found';
                matchIndicator.style.display = 'none';
                lastConfidence = 0;
                stableMatchCount = 0;
                
                // Reset to coarse mode if no matches found
                if (rotationMode !== 'coarse') {
                    rotationMode = 'coarse';
                }
            }
            
            // Clean up OpenCV resources
            templateMat.delete();
            templateGray.delete();
            blurredTemplate.delete();
            
        } catch (err) {
            console.error('Detection error:', err);
            document.getElementById('workerStatus').textContent = 'Detection Error: ' + err.message;
        } finally {
            // Update performance stats
            updatePerformanceStats(startTime);
            
            isProcessing = false;
            // Use requestAnimationFrame for smoother processing
            requestAnimationFrame(processDetection);
        }
    }
    
    // Initialization with OpenCV loading check
    document.addEventListener('DOMContentLoaded', () => {
        if (typeof cv !== 'undefined' && cv.Mat) {
            initializeApplication();
        } else {
            // Wait for OpenCV to load
            const interval = setInterval(() => {
                if (typeof cv !== 'undefined' && cv.Mat) {
                    clearInterval(interval);
                    log('OpenCV loaded, initializing application');
                    initializeApplication();
                    
                    // Set up event handlers
                    document.getElementById('upperSection').addEventListener('click', captureReferenceImage);
                    document.getElementById('lowerSection').addEventListener('dblclick', resetApplication);
                }
            }, 300);
        }
    });
</script>
</html>
